{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Victor\\miniconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import classes_functions as cf\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"shop\", \"url\", \"modelID\", \"featuresMap\", \"title\"])\n",
    "\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "\n",
    "# Load brand data https://www.kaggle.com/datasets/devsubhash/television-brands-ecommerce-dataset\n",
    "brand_df = pd.read_csv(\"./TV_Final.csv\")\n",
    "brands_ref = [i.lower().strip() for i in brand_df[[\"Brand\"]].drop_duplicates().to_numpy().flatten()] + [\"nec\", \"insignia\", \"supersonic\", \"viewsonic\", \"vizio\", \"coby\", \n",
    "                                                                                                    \"naxa\", \"rca\", \"dynex\", \"magnavox\", \"sunbritetv\", \"avue\", \n",
    "                                                                                                    \"venturer\", \"pyle\", \"westinghouse\", \"proscan\", \"sceptre\",\n",
    "                                                                                                    \"contex\", \"mitsubishi\", 'epson', \"hannspree\", \"curtisyoung\",\n",
    "                                                                                                    'hp', \"seiki\", \"azend\", \"hiteker\", \"upstar\", \"optoma\",\n",
    "                                                                                                    \"affinity\", \"viore\", \"craig\", \"elo\", \"gpx\"\n",
    "                                                                                                    ]\n",
    "brand_pattern = '|'.join(rf'\\b{re.escape(word)}\\b' for word in brands_ref)\n",
    "brand_regex_pattern = f'({brand_pattern})'\n",
    "\n",
    "# Reading the json as a dict\n",
    "with open(\"./TVs-all-merged.json\") as json_data:\n",
    "    df_dict = json.load(json_data)\n",
    "\n",
    "for k, v in df_dict.items():\n",
    "    df = pd.concat([df, pd.DataFrame(v)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hertz_list = ['hertz', ' hz', '-hz', ' hertz']\n",
    "inch_list = ['inches', ' inches', '\"', ' \"', '-inch', ' inch']\n",
    "\n",
    "df[\"l_title\"] = df[\"title\"].str.lower()\n",
    "\n",
    "df['l_title'] = df['l_title'].replace(hertz_list, 'hz', regex=True)\n",
    "df['l_title'] = df['l_title'].replace(inch_list, 'inch', regex=True)\n",
    "df['l_title'] = df['l_title'].replace(\"-\", '', regex=True)\n",
    "\n",
    "# Remove things in parenthesis (usually not the most important information)\n",
    "parenthesis_regex = r'\\([^)]*\\)'\n",
    "sq_bracket_refex = r'/\\[.*\\]/'\n",
    "df['l_title'] = df['l_title'].replace(parenthesis_regex, '', regex=True)\n",
    "df['l_title'] = df['l_title'].replace(sq_bracket_refex, '', regex=True)\n",
    "\n",
    "regex_pattern = r'([a-zA-Z0-9]*(([0-9]+[^0-9, ]+)|([^0-9, ]+[0-9]+))[a-zA-Z0-9]*)'\n",
    "matches = df['l_title'].str.extractall(regex_pattern).groupby(level=0)[0].apply(set).apply(lambda x: sorted(x))\n",
    "\n",
    "df = df.merge(matches, how='left', left_index=True, right_index=True).rename(columns={0: 'main_feature_lst'})\n",
    "\n",
    "brand_matches = df['l_title'].str.extractall(brand_regex_pattern).groupby(level=0)[0].apply(set).apply(lambda x: sorted(x))\n",
    "df = df.merge(brand_matches, how='left', left_index=True, right_index=True).rename(columns={0: 'brand'})\n",
    "\n",
    "df['appended_column'] = df.apply(lambda row: row['main_feature_lst'] + row['brand'] if not any(pd.isna(row)) else \"\", axis=1)\n",
    "df['main_feature_w_id'] = df[\"appended_column\"].apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "id_regex = r'\\b(?=\\w*\\d)(?=\\w*[a-zA-Z])(?![\\w\\d]*(?:p|hz|inch|k|d)\\b)(\\w+)\\b'\n",
    "df[\"matched_id\"] = df[\"main_feature_w_id\"].str.findall(id_regex).apply(lambda x: max(x, default=np.nan, key=cf.get_length))\n",
    "df['main_feature'] = df['main_feature_w_id'].astype(str).str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main For-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d716f9a0ca14035a2ddd48797b6602a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf3bee51a994c13a5b7e04aea384e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40121c6eca1455599e515124fbf271f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbee278df5514a0ca555505fc28630ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e97d5d5b82e44b1915ab1b5c5bd5539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e76c7a671f4bf7ac12ec228df910c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ee946b1d6c4307a69ad1905c57d3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d3ead292f149508b031947a80a6a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fd13fa4d2e466e9c0a39f80a177ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45bf630236f4689a60fc277e9189254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b683614bf66147e3982a36bf60aaf991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d4c5734d514a73b34802e514702020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f29dc7dc2445ccae38634c2a790ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shingling_size = 3\n",
    "hash_size = 8\n",
    "train_frac = 0.63\n",
    "nbr_runs = 10\n",
    "\n",
    "total_f1 = []\n",
    "total_f1_star = []\n",
    "bands = []\n",
    "fraction_of_comparisons = []\n",
    "\n",
    "for band_nbr in sorted(set([int(i) for i in np.logspace(1, 2.11, 100)])):\n",
    "\n",
    "    f1_list = []\n",
    "    f1_star_list = []\n",
    "    runtime_list = []\n",
    "    fraction_of_comparison_list = []\n",
    "\n",
    "    for i in tqdm(range(nbr_runs)):\n",
    "        f1, f1_star, confusion_matrix, all_pairs_without_dupes_test, runtime_sec, fraction_of_comparison = cf.main_run(df, train_frac, shingling_size, hash_size, band_nbr)\n",
    "        f1_list.append(f1)\n",
    "        f1_star_list.append(f1_star)\n",
    "        runtime_list.append(runtime_sec)\n",
    "        fraction_of_comparison_list.append(fraction_of_comparison)\n",
    "\n",
    "    total_f1.append(np.median(f1_list))\n",
    "    total_f1_star.append(np.median(f1_star_list))\n",
    "    fraction_of_comparisons.append(np.median(fraction_of_comparison_list))\n",
    "    bands.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
